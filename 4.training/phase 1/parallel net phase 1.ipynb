{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "scUIupOcDPED",
    "outputId": "cbc13317-422a-49bb-b1b1-f4b3fd285c62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qRKRhEsRDPEE",
    "outputId": "8a5cb512-edd0-461e-9fa2-f2107d9932ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JMTEb-7ODPEE",
    "outputId": "3c7847ab-97ce-4270-a508-6082d214342f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5ezKohxdDPEE",
    "outputId": "a9f5822f-007a-4fa2-b220-b6630f46152f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-e0T1KxpDPEF",
    "outputId": "1f50d62c-f8fc-4d28-8431-d1099b18107e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:19:18.607308: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-11 18:19:18.669562: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Built with CUDA:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Is Built with CUDA: \", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yxX5MYFxDPEF",
    "outputId": "8e953da2-674f-4e83-a336-1af7589df2d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2Yr9t27XDPEF",
    "outputId": "f0238bfe-639d-42e1-c919-fda6cc7468df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HBwMPr0hDPEF",
    "outputId": "538a05e8-d7f0-4ecb-843e-fb3f1d1e5091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yCIAaTQyh4qd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_images_and_masks(image_dir, mask_dir, limit=10):\n",
    "    image_paths = sorted([\n",
    "        os.path.join(image_dir, fname)\n",
    "        for fname in os.listdir(image_dir)\n",
    "        if fname.endswith('.png') and fname.startswith(\"x\")\n",
    "    ])[:limit]\n",
    "\n",
    "    mask_paths = sorted([\n",
    "        os.path.join(mask_dir, fname)\n",
    "        for fname in os.listdir(mask_dir)\n",
    "        if fname.endswith('.png') and fname.startswith(\"y\")\n",
    "    ])[:limit]\n",
    "\n",
    "    images = [np.array(Image.open(path).convert(\"L\")) / 255.0 for path in image_paths]\n",
    "    images = [image.reshape(512, 512, 1) for image in images]\n",
    "    masks = [np.array(Image.open(path).convert(\"L\")) for path in mask_paths]\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        masks[i][mask == 127] = 1  # Class 1\n",
    "        masks[i][mask == 255] = 2  # Class 2\n",
    "        masks[i] = to_categorical(masks[i], num_classes=3)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "X, Y = load_images_and_masks(\"x\", \"y\", 1032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BOP74IifDPEG",
    "outputId": "b8570f77-dca4-4931-ccad-8bd6d10acdd5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1032, 512, 512, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rFJ_R7ElDPEG",
    "outputId": "f9d2881a-3684-46f4-f32e-03933edc6b2c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1032, 512, 512, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QVTM10Gmk3tE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EaqkNrWEDPEH",
    "outputId": "9703c061-d513-4776-8849-5771276a3a9b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 512, 512, 1)\n",
      "Train size: (825, 512, 512, 1), (825, 512, 512, 3)\n",
      "Val size: (103, 512, 512, 1), (103, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(f\"Train size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Val size: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sZzFE_LFmqZV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, concatenate, Dropout, MaxPooling2D, UpSampling2D, PReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def parallel_net_segmentation(input_size=(512, 512, 1), num_classes=3):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # First parallel block\n",
    "    path_a1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    path_a1 = PReLU()(path_a1)\n",
    "    path_b1 = Conv2D(64, (5, 5), padding='same')(inputs)\n",
    "    path_b1 = PReLU()(path_b1)\n",
    "    merged1 = concatenate([path_a1, path_b1], axis=3)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(merged1)\n",
    "\n",
    "    # Second parallel block\n",
    "    path_a2 = Conv2D(128, (3, 3), padding='same')(pool1)\n",
    "    path_a2 = PReLU()(path_a2)\n",
    "    path_b2 = Conv2D(128, (5, 5), padding='same')(pool1)\n",
    "    path_b2 = PReLU()(path_b2)\n",
    "    merged2 = concatenate([path_a2, path_b2], axis=3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(merged2)\n",
    "\n",
    "    # Third parallel block\n",
    "    path_a3 = Conv2D(256, (3, 3), padding='same')(pool2)\n",
    "    path_a3 = PReLU()(path_a3)\n",
    "    path_b3 = Conv2D(256, (5, 5), padding='same')(pool2)\n",
    "    path_b3 = PReLU()(path_b3)\n",
    "    merged3 = concatenate([path_a3, path_b3], axis=3)\n",
    "    drop3 = Dropout(0.5)(merged3)\n",
    "\n",
    "    # Upsampling and skip connection 1\n",
    "    upsample1 = UpSampling2D(size=(2, 2))(drop3)\n",
    "    skip1 = concatenate([upsample1, merged2], axis=3)\n",
    "\n",
    "    # Fourth parallel block with skip connection\n",
    "    path_a4 = Conv2D(128, (3, 3), padding='same')(skip1)\n",
    "    path_a4 = PReLU()(path_a4)\n",
    "    path_b4 = Conv2D(128, (5, 5), padding='same')(skip1)\n",
    "    path_b4 = PReLU()(path_b4)\n",
    "    merged4 = concatenate([path_a4, path_b4], axis=3)\n",
    "\n",
    "    # Upsampling and skip connection 2\n",
    "    upsample2 = UpSampling2D(size=(2, 2))(merged4)\n",
    "    skip2 = concatenate([upsample2, merged1], axis=3)\n",
    "\n",
    "    # Fifth parallel block with skip connection\n",
    "    path_a5 = Conv2D(64, (3, 3), padding='same')(skip2)\n",
    "    path_a5 = PReLU()(path_a5)\n",
    "    path_b5 = Conv2D(64, (5, 5), padding='same')(skip2)\n",
    "    path_b5 = PReLU()(path_b5)\n",
    "    merged5 = concatenate([path_a5, path_b5], axis=3)\n",
    "\n",
    "    # Final convolutional layer for segmentation\n",
    "    output = Conv2D(num_classes, (1, 1), activation='softmax')(merged5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vxWmF1dInWFF",
    "outputId": "7a4b8b7f-ea21-4563-f095-89079db02af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:19:38.586277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
      "2023-12-11 18:19:38.588919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 20609 MB memory:  -> device: 1, name: NVIDIA L4, pci bus id: 0000:00:04.0, compute capability: 8.9\n",
      "2023-12-11 18:19:38.590772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20609 MB memory:  -> device: 2, name: NVIDIA L4, pci bus id: 0000:00:05.0, compute capability: 8.9\n",
      "2023-12-11 18:19:38.593202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 20609 MB memory:  -> device: 3, name: NVIDIA L4, pci bus id: 0000:00:06.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Recall, Precision, MeanIoU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "\n",
    "smooth = 1e-6  # To avoid division by zero\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6  # To avoid division by zero\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = tf.keras.backend.sum(tf.keras.backend.abs(y_true) + tf.keras.backend.abs(y_pred), axis=-1)\n",
    "    iou = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return iou\n",
    "\n",
    "def combined_dice_crossentropy_loss(y_true, y_pred, dice_loss_weight=0.5):\n",
    "    # Dice Loss\n",
    "    dice_loss_value = dice_loss(y_true, y_pred)\n",
    "\n",
    "    # Categorical Cross-Entropy Loss\n",
    "    cross_entropy_loss_value = categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Combined Loss\n",
    "    combined_loss = dice_loss_weight * dice_loss_value + (1 - dice_loss_weight) * cross_entropy_loss_value\n",
    "    return combined_loss\n",
    "\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model = parallel_net_segmentation()\n",
    "    optimizer = Adam(learning_rate=2e-4)  # Example learning rate\n",
    "    model.compile(optimizer=optimizer, loss=combined_dice_crossentropy_loss, metrics=[\"accuracy\", dice_coefficient, iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAqmdu7knZad",
    "outputId": "edb6d8c9-df5b-4cd9-973c-df98649e39e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "INFO:tensorflow:Collective all_reduce tensors: 32 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 32 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:19:58.052339: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-12-11 18:20:01.440998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n",
      "2023-12-11 18:20:02.550893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n",
      "2023-12-11 18:20:03.567842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n",
      "2023-12-11 18:20:04.446478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n",
      "2023-12-11 18:20:07.666343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-11 18:20:26.250755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f890bcd0890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-11 18:20:26.250796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2023-12-11 18:20:26.250802: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA L4, Compute Capability 8.9\n",
      "2023-12-11 18:20:26.250807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA L4, Compute Capability 8.9\n",
      "2023-12-11 18:20:26.250811: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA L4, Compute Capability 8.9\n",
      "2023-12-11 18:20:26.265031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-11 18:20:26.403564: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.7770 - dice_coefficient: 0.7064 - iou: 0.6346\n",
      "Epoch 1: val_loss improved from inf to 0.32086, saving model to model_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 145s 991ms/step - loss: 0.4116 - accuracy: 0.7770 - dice_coefficient: 0.7064 - iou: 0.6346 - val_loss: 0.3209 - val_accuracy: 0.8214 - val_dice_coefficient: 0.7712 - val_iou: 0.7117 - lr: 2.0000e-04\n",
      "Epoch 2/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8320 - dice_coefficient: 0.7918 - iou: 0.7336\n",
      "Epoch 2: val_loss improved from 0.32086 to 0.29612, saving model to model_best.h5\n",
      "104/104 [==============================] - 94s 908ms/step - loss: 0.2965 - accuracy: 0.8320 - dice_coefficient: 0.7918 - iou: 0.7336 - val_loss: 0.2961 - val_accuracy: 0.8350 - val_dice_coefficient: 0.7824 - val_iou: 0.7210 - lr: 2.0000e-04\n",
      "Epoch 3/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.8476 - dice_coefficient: 0.8108 - iou: 0.7567\n",
      "Epoch 3: val_loss improved from 0.29612 to 0.27957, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 927ms/step - loss: 0.2692 - accuracy: 0.8476 - dice_coefficient: 0.8108 - iou: 0.7567 - val_loss: 0.2796 - val_accuracy: 0.8443 - val_dice_coefficient: 0.8043 - val_iou: 0.7532 - lr: 2.0000e-04\n",
      "Epoch 4/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.8800 - dice_coefficient: 0.8432 - iou: 0.7963\n",
      "Epoch 4: val_loss improved from 0.27957 to 0.25942, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 925ms/step - loss: 0.2241 - accuracy: 0.8800 - dice_coefficient: 0.8432 - iou: 0.7963 - val_loss: 0.2594 - val_accuracy: 0.8525 - val_dice_coefficient: 0.8184 - val_iou: 0.7702 - lr: 2.0000e-04\n",
      "Epoch 5/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.8966 - dice_coefficient: 0.8642 - iou: 0.8238\n",
      "Epoch 5: val_loss improved from 0.25942 to 0.18801, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 918ms/step - loss: 0.1985 - accuracy: 0.8966 - dice_coefficient: 0.8642 - iou: 0.8238 - val_loss: 0.1880 - val_accuracy: 0.9037 - val_dice_coefficient: 0.8680 - val_iou: 0.8277 - lr: 2.0000e-04\n",
      "Epoch 6/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9060 - dice_coefficient: 0.8752 - iou: 0.8366\n",
      "Epoch 6: val_loss improved from 0.18801 to 0.17678, saving model to model_best.h5\n",
      "104/104 [==============================] - 94s 907ms/step - loss: 0.1833 - accuracy: 0.9060 - dice_coefficient: 0.8752 - iou: 0.8366 - val_loss: 0.1768 - val_accuracy: 0.9100 - val_dice_coefficient: 0.8778 - val_iou: 0.8404 - lr: 2.0000e-04\n",
      "Epoch 7/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9140 - dice_coefficient: 0.8865 - iou: 0.8514\n",
      "Epoch 7: val_loss improved from 0.17678 to 0.17568, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 922ms/step - loss: 0.1694 - accuracy: 0.9140 - dice_coefficient: 0.8865 - iou: 0.8514 - val_loss: 0.1757 - val_accuracy: 0.9100 - val_dice_coefficient: 0.8806 - val_iou: 0.8448 - lr: 2.0000e-04\n",
      "Epoch 8/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9202 - dice_coefficient: 0.8941 - iou: 0.8608\n",
      "Epoch 8: val_loss improved from 0.17568 to 0.15979, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 914ms/step - loss: 0.1576 - accuracy: 0.9202 - dice_coefficient: 0.8941 - iou: 0.8608 - val_loss: 0.1598 - val_accuracy: 0.9186 - val_dice_coefficient: 0.8909 - val_iou: 0.8566 - lr: 2.0000e-04\n",
      "Epoch 9/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9253 - dice_coefficient: 0.9007 - iou: 0.8691\n",
      "Epoch 9: val_loss improved from 0.15979 to 0.15281, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 911ms/step - loss: 0.1481 - accuracy: 0.9253 - dice_coefficient: 0.9007 - iou: 0.8691 - val_loss: 0.1528 - val_accuracy: 0.9216 - val_dice_coefficient: 0.9001 - val_iou: 0.8712 - lr: 2.0000e-04\n",
      "Epoch 10/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9299 - dice_coefficient: 0.9069 - iou: 0.8772\n",
      "Epoch 10: val_loss did not improve from 0.15281\n",
      "104/104 [==============================] - 82s 793ms/step - loss: 0.1396 - accuracy: 0.9299 - dice_coefficient: 0.9069 - iou: 0.8772 - val_loss: 0.1769 - val_accuracy: 0.9084 - val_dice_coefficient: 0.8912 - val_iou: 0.8638 - lr: 2.0000e-04\n",
      "Epoch 11/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9312 - dice_coefficient: 0.9086 - iou: 0.8793\n",
      "Epoch 11: val_loss improved from 0.15281 to 0.14386, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 928ms/step - loss: 0.1371 - accuracy: 0.9312 - dice_coefficient: 0.9086 - iou: 0.8793 - val_loss: 0.1439 - val_accuracy: 0.9277 - val_dice_coefficient: 0.9020 - val_iou: 0.8702 - lr: 2.0000e-04\n",
      "Epoch 12/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9380 - dice_coefficient: 0.9172 - iou: 0.8903\n",
      "Epoch 12: val_loss did not improve from 0.14386\n",
      "104/104 [==============================] - 82s 786ms/step - loss: 0.1243 - accuracy: 0.9380 - dice_coefficient: 0.9172 - iou: 0.8903 - val_loss: 0.1608 - val_accuracy: 0.9177 - val_dice_coefficient: 0.8951 - val_iou: 0.8645 - lr: 2.0000e-04\n",
      "Epoch 13/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9390 - dice_coefficient: 0.9187 - iou: 0.8922\n",
      "Epoch 13: val_loss improved from 0.14386 to 0.12480, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 911ms/step - loss: 0.1219 - accuracy: 0.9390 - dice_coefficient: 0.9187 - iou: 0.8922 - val_loss: 0.1248 - val_accuracy: 0.9374 - val_dice_coefficient: 0.9155 - val_iou: 0.8882 - lr: 2.0000e-04\n",
      "Epoch 14/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9428 - dice_coefficient: 0.9236 - iou: 0.8987\n",
      "Epoch 14: val_loss improved from 0.12480 to 0.12224, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 919ms/step - loss: 0.1143 - accuracy: 0.9428 - dice_coefficient: 0.9236 - iou: 0.8987 - val_loss: 0.1222 - val_accuracy: 0.9388 - val_dice_coefficient: 0.9171 - val_iou: 0.8899 - lr: 2.0000e-04\n",
      "Epoch 15/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9438 - dice_coefficient: 0.9250 - iou: 0.9005\n",
      "Epoch 15: val_loss improved from 0.12224 to 0.11915, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 925ms/step - loss: 0.1127 - accuracy: 0.9438 - dice_coefficient: 0.9250 - iou: 0.9005 - val_loss: 0.1192 - val_accuracy: 0.9404 - val_dice_coefficient: 0.9186 - val_iou: 0.8917 - lr: 2.0000e-04\n",
      "Epoch 16/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9451 - dice_coefficient: 0.9272 - iou: 0.9037\n",
      "Epoch 16: val_loss did not improve from 0.11915\n",
      "104/104 [==============================] - 84s 810ms/step - loss: 0.1099 - accuracy: 0.9451 - dice_coefficient: 0.9272 - iou: 0.9037 - val_loss: 0.1221 - val_accuracy: 0.9389 - val_dice_coefficient: 0.9165 - val_iou: 0.8890 - lr: 2.0000e-04\n",
      "Epoch 17/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9493 - dice_coefficient: 0.9317 - iou: 0.9090\n",
      "Epoch 17: val_loss improved from 0.11915 to 0.10813, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 924ms/step - loss: 0.1022 - accuracy: 0.9493 - dice_coefficient: 0.9317 - iou: 0.9090 - val_loss: 0.1081 - val_accuracy: 0.9461 - val_dice_coefficient: 0.9270 - val_iou: 0.9030 - lr: 2.0000e-04\n",
      "Epoch 18/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9510 - dice_coefficient: 0.9345 - iou: 0.9129\n",
      "Epoch 18: val_loss did not improve from 0.10813\n",
      "104/104 [==============================] - 82s 788ms/step - loss: 0.0984 - accuracy: 0.9510 - dice_coefficient: 0.9345 - iou: 0.9129 - val_loss: 0.1130 - val_accuracy: 0.9433 - val_dice_coefficient: 0.9261 - val_iou: 0.9033 - lr: 2.0000e-04\n",
      "Epoch 19/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9526 - dice_coefficient: 0.9364 - iou: 0.9154\n",
      "Epoch 19: val_loss improved from 0.10813 to 0.10699, saving model to model_best.h5\n",
      "104/104 [==============================] - 94s 909ms/step - loss: 0.0956 - accuracy: 0.9526 - dice_coefficient: 0.9364 - iou: 0.9154 - val_loss: 0.1070 - val_accuracy: 0.9467 - val_dice_coefficient: 0.9290 - val_iou: 0.9063 - lr: 2.0000e-04\n",
      "Epoch 20/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9543 - dice_coefficient: 0.9386 - iou: 0.9182\n",
      "Epoch 20: val_loss improved from 0.10699 to 0.10550, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 917ms/step - loss: 0.0920 - accuracy: 0.9543 - dice_coefficient: 0.9386 - iou: 0.9182 - val_loss: 0.1055 - val_accuracy: 0.9477 - val_dice_coefficient: 0.9315 - val_iou: 0.9100 - lr: 2.0000e-04\n",
      "Epoch 21/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9544 - dice_coefficient: 0.9389 - iou: 0.9187\n",
      "Epoch 21: val_loss improved from 0.10550 to 0.10411, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 924ms/step - loss: 0.0917 - accuracy: 0.9544 - dice_coefficient: 0.9389 - iou: 0.9187 - val_loss: 0.1041 - val_accuracy: 0.9483 - val_dice_coefficient: 0.9334 - val_iou: 0.9131 - lr: 2.0000e-04\n",
      "Epoch 22/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9567 - dice_coefficient: 0.9421 - iou: 0.9230\n",
      "Epoch 22: val_loss did not improve from 0.10411\n",
      "104/104 [==============================] - 83s 794ms/step - loss: 0.0873 - accuracy: 0.9567 - dice_coefficient: 0.9421 - iou: 0.9230 - val_loss: 0.1133 - val_accuracy: 0.9432 - val_dice_coefficient: 0.9284 - val_iou: 0.9075 - lr: 2.0000e-04\n",
      "Epoch 23/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9549 - dice_coefficient: 0.9398 - iou: 0.9199\n",
      "Epoch 23: val_loss improved from 0.10411 to 0.10194, saving model to model_best.h5\n",
      "104/104 [==============================] - 94s 907ms/step - loss: 0.0907 - accuracy: 0.9549 - dice_coefficient: 0.9398 - iou: 0.9199 - val_loss: 0.1019 - val_accuracy: 0.9494 - val_dice_coefficient: 0.9349 - val_iou: 0.9152 - lr: 2.0000e-04\n",
      "Epoch 24/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9595 - dice_coefficient: 0.9455 - iou: 0.9272\n",
      "Epoch 24: val_loss improved from 0.10194 to 0.09847, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 911ms/step - loss: 0.0820 - accuracy: 0.9595 - dice_coefficient: 0.9455 - iou: 0.9272 - val_loss: 0.0985 - val_accuracy: 0.9518 - val_dice_coefficient: 0.9405 - val_iou: 0.9238 - lr: 2.0000e-04\n",
      "Epoch 25/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9608 - dice_coefficient: 0.9473 - iou: 0.9297\n",
      "Epoch 25: val_loss improved from 0.09847 to 0.09470, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 915ms/step - loss: 0.0792 - accuracy: 0.9608 - dice_coefficient: 0.9473 - iou: 0.9297 - val_loss: 0.0947 - val_accuracy: 0.9533 - val_dice_coefficient: 0.9402 - val_iou: 0.9222 - lr: 2.0000e-04\n",
      "Epoch 26/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9619 - dice_coefficient: 0.9489 - iou: 0.9318\n",
      "Epoch 26: val_loss did not improve from 0.09470\n",
      "104/104 [==============================] - 82s 793ms/step - loss: 0.0770 - accuracy: 0.9619 - dice_coefficient: 0.9489 - iou: 0.9318 - val_loss: 0.0984 - val_accuracy: 0.9513 - val_dice_coefficient: 0.9359 - val_iou: 0.9155 - lr: 2.0000e-04\n",
      "Epoch 27/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9614 - dice_coefficient: 0.9482 - iou: 0.9310\n",
      "Epoch 27: val_loss did not improve from 0.09470\n",
      "104/104 [==============================] - 83s 796ms/step - loss: 0.0781 - accuracy: 0.9614 - dice_coefficient: 0.9482 - iou: 0.9310 - val_loss: 0.0971 - val_accuracy: 0.9526 - val_dice_coefficient: 0.9416 - val_iou: 0.9254 - lr: 2.0000e-04\n",
      "Epoch 28/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9621 - dice_coefficient: 0.9493 - iou: 0.9324\n",
      "Epoch 28: val_loss did not improve from 0.09470\n",
      "104/104 [==============================] - 83s 796ms/step - loss: 0.0766 - accuracy: 0.9621 - dice_coefficient: 0.9493 - iou: 0.9324 - val_loss: 0.1030 - val_accuracy: 0.9488 - val_dice_coefficient: 0.9349 - val_iou: 0.9156 - lr: 2.0000e-04\n",
      "Epoch 29/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9639 - dice_coefficient: 0.9514 - iou: 0.9351\n",
      "Epoch 29: val_loss improved from 0.09470 to 0.09209, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 910ms/step - loss: 0.0730 - accuracy: 0.9639 - dice_coefficient: 0.9514 - iou: 0.9351 - val_loss: 0.0921 - val_accuracy: 0.9549 - val_dice_coefficient: 0.9434 - val_iou: 0.9270 - lr: 2.0000e-04\n",
      "Epoch 30/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9655 - dice_coefficient: 0.9536 - iou: 0.9380\n",
      "Epoch 30: val_loss improved from 0.09209 to 0.09201, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 916ms/step - loss: 0.0699 - accuracy: 0.9655 - dice_coefficient: 0.9536 - iou: 0.9380 - val_loss: 0.0920 - val_accuracy: 0.9549 - val_dice_coefficient: 0.9428 - val_iou: 0.9257 - lr: 2.0000e-04\n",
      "Epoch 31/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9659 - dice_coefficient: 0.9541 - iou: 0.9387\n",
      "Epoch 31: val_loss improved from 0.09201 to 0.08982, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 910ms/step - loss: 0.0691 - accuracy: 0.9659 - dice_coefficient: 0.9541 - iou: 0.9387 - val_loss: 0.0898 - val_accuracy: 0.9561 - val_dice_coefficient: 0.9450 - val_iou: 0.9291 - lr: 2.0000e-04\n",
      "Epoch 32/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9668 - dice_coefficient: 0.9552 - iou: 0.9401\n",
      "Epoch 32: val_loss did not improve from 0.08982\n",
      "104/104 [==============================] - 83s 800ms/step - loss: 0.0674 - accuracy: 0.9668 - dice_coefficient: 0.9552 - iou: 0.9401 - val_loss: 0.0954 - val_accuracy: 0.9538 - val_dice_coefficient: 0.9442 - val_iou: 0.9294 - lr: 2.0000e-04\n",
      "Epoch 33/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9669 - dice_coefficient: 0.9555 - iou: 0.9406\n",
      "Epoch 33: val_loss did not improve from 0.08982\n",
      "104/104 [==============================] - 82s 791ms/step - loss: 0.0670 - accuracy: 0.9669 - dice_coefficient: 0.9555 - iou: 0.9406 - val_loss: 0.0908 - val_accuracy: 0.9558 - val_dice_coefficient: 0.9455 - val_iou: 0.9302 - lr: 2.0000e-04\n",
      "Epoch 34/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9679 - dice_coefficient: 0.9568 - iou: 0.9423\n",
      "Epoch 34: val_loss did not improve from 0.08982\n",
      "104/104 [==============================] - 82s 791ms/step - loss: 0.0650 - accuracy: 0.9679 - dice_coefficient: 0.9568 - iou: 0.9423 - val_loss: 0.0926 - val_accuracy: 0.9554 - val_dice_coefficient: 0.9453 - val_iou: 0.9302 - lr: 2.0000e-04\n",
      "Epoch 35/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9684 - dice_coefficient: 0.9575 - iou: 0.9432\n",
      "Epoch 35: val_loss improved from 0.08982 to 0.08860, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 915ms/step - loss: 0.0640 - accuracy: 0.9684 - dice_coefficient: 0.9575 - iou: 0.9432 - val_loss: 0.0886 - val_accuracy: 0.9570 - val_dice_coefficient: 0.9458 - val_iou: 0.9299 - lr: 2.0000e-04\n",
      "Epoch 36/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9691 - dice_coefficient: 0.9584 - iou: 0.9444\n",
      "Epoch 36: val_loss did not improve from 0.08860\n",
      "104/104 [==============================] - 83s 798ms/step - loss: 0.0626 - accuracy: 0.9691 - dice_coefficient: 0.9584 - iou: 0.9444 - val_loss: 0.0897 - val_accuracy: 0.9569 - val_dice_coefficient: 0.9463 - val_iou: 0.9311 - lr: 2.0000e-04\n",
      "Epoch 37/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9699 - dice_coefficient: 0.9595 - iou: 0.9459\n",
      "Epoch 37: val_loss did not improve from 0.08860\n",
      "104/104 [==============================] - 84s 811ms/step - loss: 0.0611 - accuracy: 0.9699 - dice_coefficient: 0.9595 - iou: 0.9459 - val_loss: 0.0933 - val_accuracy: 0.9552 - val_dice_coefficient: 0.9453 - val_iou: 0.9304 - lr: 2.0000e-04\n",
      "Epoch 38/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9694 - dice_coefficient: 0.9589 - iou: 0.9451\n",
      "Epoch 38: val_loss improved from 0.08860 to 0.08687, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 923ms/step - loss: 0.0635 - accuracy: 0.9694 - dice_coefficient: 0.9589 - iou: 0.9451 - val_loss: 0.0869 - val_accuracy: 0.9582 - val_dice_coefficient: 0.9481 - val_iou: 0.9334 - lr: 2.0000e-04\n",
      "Epoch 39/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9713 - dice_coefficient: 0.9614 - iou: 0.9483\n",
      "Epoch 39: val_loss did not improve from 0.08687\n",
      "104/104 [==============================] - 82s 788ms/step - loss: 0.0581 - accuracy: 0.9713 - dice_coefficient: 0.9614 - iou: 0.9483 - val_loss: 0.0898 - val_accuracy: 0.9576 - val_dice_coefficient: 0.9479 - val_iou: 0.9337 - lr: 2.0000e-04\n",
      "Epoch 40/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9719 - dice_coefficient: 0.9620 - iou: 0.9492\n",
      "Epoch 40: val_loss did not improve from 0.08687\n",
      "104/104 [==============================] - 83s 799ms/step - loss: 0.0571 - accuracy: 0.9719 - dice_coefficient: 0.9620 - iou: 0.9492 - val_loss: 0.0878 - val_accuracy: 0.9583 - val_dice_coefficient: 0.9492 - val_iou: 0.9355 - lr: 2.0000e-04\n",
      "Epoch 41/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9727 - dice_coefficient: 0.9631 - iou: 0.9507\n",
      "Epoch 41: val_loss did not improve from 0.08687\n",
      "104/104 [==============================] - 82s 790ms/step - loss: 0.0554 - accuracy: 0.9727 - dice_coefficient: 0.9631 - iou: 0.9507 - val_loss: 0.0897 - val_accuracy: 0.9574 - val_dice_coefficient: 0.9474 - val_iou: 0.9328 - lr: 2.0000e-04\n",
      "Epoch 42/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9731 - dice_coefficient: 0.9636 - iou: 0.9513\n",
      "Epoch 42: val_loss improved from 0.08687 to 0.08456, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 917ms/step - loss: 0.0546 - accuracy: 0.9731 - dice_coefficient: 0.9636 - iou: 0.9513 - val_loss: 0.0846 - val_accuracy: 0.9598 - val_dice_coefficient: 0.9507 - val_iou: 0.9372 - lr: 2.0000e-04\n",
      "Epoch 43/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9731 - dice_coefficient: 0.9638 - iou: 0.9516\n",
      "Epoch 43: val_loss did not improve from 0.08456\n",
      "104/104 [==============================] - 83s 802ms/step - loss: 0.0544 - accuracy: 0.9731 - dice_coefficient: 0.9638 - iou: 0.9516 - val_loss: 0.0858 - val_accuracy: 0.9595 - val_dice_coefficient: 0.9499 - val_iou: 0.9360 - lr: 2.0000e-04\n",
      "Epoch 44/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9741 - dice_coefficient: 0.9650 - iou: 0.9532\n",
      "Epoch 44: val_loss did not improve from 0.08456\n",
      "104/104 [==============================] - 83s 801ms/step - loss: 0.0525 - accuracy: 0.9741 - dice_coefficient: 0.9650 - iou: 0.9532 - val_loss: 0.0849 - val_accuracy: 0.9606 - val_dice_coefficient: 0.9528 - val_iou: 0.9407 - lr: 2.0000e-04\n",
      "Epoch 45/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9750 - dice_coefficient: 0.9662 - iou: 0.9548\n",
      "Epoch 45: val_loss did not improve from 0.08456\n",
      "104/104 [==============================] - 82s 787ms/step - loss: 0.0508 - accuracy: 0.9750 - dice_coefficient: 0.9662 - iou: 0.9548 - val_loss: 0.0865 - val_accuracy: 0.9596 - val_dice_coefficient: 0.9505 - val_iou: 0.9370 - lr: 2.0000e-04\n",
      "Epoch 46/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9750 - dice_coefficient: 0.9662 - iou: 0.9548\n",
      "Epoch 46: val_loss did not improve from 0.08456\n",
      "104/104 [==============================] - 84s 809ms/step - loss: 0.0507 - accuracy: 0.9750 - dice_coefficient: 0.9662 - iou: 0.9548 - val_loss: 0.0847 - val_accuracy: 0.9606 - val_dice_coefficient: 0.9521 - val_iou: 0.9393 - lr: 2.0000e-04\n",
      "Epoch 47/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9755 - dice_coefficient: 0.9670 - iou: 0.9558\n",
      "Epoch 47: val_loss did not improve from 0.08456\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00015999999595806003.\n",
      "104/104 [==============================] - 82s 790ms/step - loss: 0.0496 - accuracy: 0.9755 - dice_coefficient: 0.9670 - iou: 0.9558 - val_loss: 0.0846 - val_accuracy: 0.9606 - val_dice_coefficient: 0.9516 - val_iou: 0.9383 - lr: 2.0000e-04\n",
      "Epoch 48/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9763 - dice_coefficient: 0.9679 - iou: 0.9570\n",
      "Epoch 48: val_loss improved from 0.08456 to 0.08455, saving model to model_best.h5\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9769 - dice_coefficient: 0.9688 - iou: 0.9581\n",
      "Epoch 49: val_loss did not improve from 0.08455\n",
      "104/104 [==============================] - 84s 804ms/step - loss: 0.0468 - accuracy: 0.9769 - dice_coefficient: 0.9688 - iou: 0.9581 - val_loss: 0.0852 - val_accuracy: 0.9610 - val_dice_coefficient: 0.9533 - val_iou: 0.9413 - lr: 1.6000e-04\n",
      "Epoch 50/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9775 - dice_coefficient: 0.9694 - iou: 0.9590\n",
      "Epoch 50: val_loss improved from 0.08455 to 0.08405, saving model to model_best.h5\n",
      "104/104 [==============================] - 96s 925ms/step - loss: 0.0458 - accuracy: 0.9775 - dice_coefficient: 0.9694 - iou: 0.9590 - val_loss: 0.0841 - val_accuracy: 0.9615 - val_dice_coefficient: 0.9542 - val_iou: 0.9426 - lr: 1.6000e-04\n",
      "Epoch 51/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9776 - dice_coefficient: 0.9697 - iou: 0.9594\n",
      "Epoch 51: val_loss did not improve from 0.08405\n",
      "104/104 [==============================] - 83s 798ms/step - loss: 0.0455 - accuracy: 0.9776 - dice_coefficient: 0.9697 - iou: 0.9594 - val_loss: 0.0864 - val_accuracy: 0.9601 - val_dice_coefficient: 0.9520 - val_iou: 0.9395 - lr: 1.6000e-04\n",
      "Epoch 52/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9776 - dice_coefficient: 0.9696 - iou: 0.9593\n",
      "Epoch 52: val_loss did not improve from 0.08405\n",
      "104/104 [==============================] - 83s 800ms/step - loss: 0.0454 - accuracy: 0.9776 - dice_coefficient: 0.9696 - iou: 0.9593 - val_loss: 0.0894 - val_accuracy: 0.9595 - val_dice_coefficient: 0.9516 - val_iou: 0.9392 - lr: 1.6000e-04\n",
      "Epoch 53/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9756 - dice_coefficient: 0.9673 - iou: 0.9563\n",
      "Epoch 53: val_loss did not improve from 0.08405\n",
      "104/104 [==============================] - 83s 799ms/step - loss: 0.0493 - accuracy: 0.9756 - dice_coefficient: 0.9673 - iou: 0.9563 - val_loss: 0.0873 - val_accuracy: 0.9597 - val_dice_coefficient: 0.9515 - val_iou: 0.9389 - lr: 1.6000e-04\n",
      "Epoch 54/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9782 - dice_coefficient: 0.9704 - iou: 0.9603\n",
      "Epoch 54: val_loss did not improve from 0.08405\n",
      "104/104 [==============================] - 83s 797ms/step - loss: 0.0442 - accuracy: 0.9782 - dice_coefficient: 0.9704 - iou: 0.9603 - val_loss: 0.0847 - val_accuracy: 0.9615 - val_dice_coefficient: 0.9542 - val_iou: 0.9426 - lr: 1.6000e-04\n",
      "Epoch 55/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9790 - dice_coefficient: 0.9715 - iou: 0.9617\n",
      "Epoch 55: val_loss did not improve from 0.08405\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012799999676644803.\n",
      "104/104 [==============================] - 83s 793ms/step - loss: 0.0426 - accuracy: 0.9790 - dice_coefficient: 0.9715 - iou: 0.9617 - val_loss: 0.0856 - val_accuracy: 0.9620 - val_dice_coefficient: 0.9555 - val_iou: 0.9447 - lr: 1.6000e-04\n",
      "Epoch 56/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9793 - dice_coefficient: 0.9719 - iou: 0.9623\n",
      "Epoch 56: val_loss did not improve from 0.08405\n",
      "104/104 [==============================] - 83s 796ms/step - loss: 0.0419 - accuracy: 0.9793 - dice_coefficient: 0.9719 - iou: 0.9623 - val_loss: 0.0841 - val_accuracy: 0.9625 - val_dice_coefficient: 0.9559 - val_iou: 0.9451 - lr: 1.2800e-04\n",
      "Epoch 57/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9799 - dice_coefficient: 0.9726 - iou: 0.9633\n",
      "Epoch 57: val_loss improved from 0.08405 to 0.08388, saving model to model_best.h5\n",
      "104/104 [==============================] - 95s 919ms/step - loss: 0.0408 - accuracy: 0.9799 - dice_coefficient: 0.9726 - iou: 0.9633 - val_loss: 0.0839 - val_accuracy: 0.9625 - val_dice_coefficient: 0.9557 - val_iou: 0.9447 - lr: 1.2800e-04\n",
      "Epoch 58/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9801 - dice_coefficient: 0.9730 - iou: 0.9637\n",
      "Epoch 58: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 82s 791ms/step - loss: 0.0404 - accuracy: 0.9801 - dice_coefficient: 0.9730 - iou: 0.9637 - val_loss: 0.0854 - val_accuracy: 0.9621 - val_dice_coefficient: 0.9557 - val_iou: 0.9450 - lr: 1.2800e-04\n",
      "Epoch 59/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9802 - dice_coefficient: 0.9731 - iou: 0.9639\n",
      "Epoch 59: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 82s 792ms/step - loss: 0.0401 - accuracy: 0.9802 - dice_coefficient: 0.9731 - iou: 0.9639 - val_loss: 0.0861 - val_accuracy: 0.9622 - val_dice_coefficient: 0.9560 - val_iou: 0.9455 - lr: 1.2800e-04\n",
      "Epoch 60/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9806 - dice_coefficient: 0.9737 - iou: 0.9646\n",
      "Epoch 60: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 83s 794ms/step - loss: 0.0393 - accuracy: 0.9806 - dice_coefficient: 0.9737 - iou: 0.9646 - val_loss: 0.0874 - val_accuracy: 0.9619 - val_dice_coefficient: 0.9557 - val_iou: 0.9454 - lr: 1.2800e-04\n",
      "Epoch 61/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9806 - dice_coefficient: 0.9737 - iou: 0.9648\n",
      "Epoch 61: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 82s 788ms/step - loss: 0.0392 - accuracy: 0.9806 - dice_coefficient: 0.9737 - iou: 0.9648 - val_loss: 0.0853 - val_accuracy: 0.9627 - val_dice_coefficient: 0.9567 - val_iou: 0.9464 - lr: 1.2800e-04\n",
      "Epoch 62/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9810 - dice_coefficient: 0.9743 - iou: 0.9655\n",
      "Epoch 62: val_loss did not improve from 0.08388\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00010239999974146486.\n",
      "104/104 [==============================] - 83s 798ms/step - loss: 0.0383 - accuracy: 0.9810 - dice_coefficient: 0.9743 - iou: 0.9655 - val_loss: 0.0865 - val_accuracy: 0.9623 - val_dice_coefficient: 0.9560 - val_iou: 0.9455 - lr: 1.2800e-04\n",
      "Epoch 63/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9814 - dice_coefficient: 0.9748 - iou: 0.9661\n",
      "Epoch 63: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 82s 791ms/step - loss: 0.0376 - accuracy: 0.9814 - dice_coefficient: 0.9748 - iou: 0.9661 - val_loss: 0.0856 - val_accuracy: 0.9628 - val_dice_coefficient: 0.9568 - val_iou: 0.9466 - lr: 1.0240e-04\n",
      "Epoch 64/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9814 - dice_coefficient: 0.9749 - iou: 0.9663\n",
      "Epoch 64: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 84s 805ms/step - loss: 0.0375 - accuracy: 0.9814 - dice_coefficient: 0.9749 - iou: 0.9663 - val_loss: 0.0881 - val_accuracy: 0.9612 - val_dice_coefficient: 0.9548 - val_iou: 0.9441 - lr: 1.0240e-04\n",
      "Epoch 65/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9816 - dice_coefficient: 0.9750 - iou: 0.9664\n",
      "Epoch 65: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 82s 791ms/step - loss: 0.0372 - accuracy: 0.9816 - dice_coefficient: 0.9750 - iou: 0.9664 - val_loss: 0.0891 - val_accuracy: 0.9619 - val_dice_coefficient: 0.9562 - val_iou: 0.9463 - lr: 1.0240e-04\n",
      "Epoch 66/200\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9819 - dice_coefficient: 0.9755 - iou: 0.9671\n",
      "Epoch 66: val_loss did not improve from 0.08388\n",
      "104/104 [==============================] - 84s 806ms/step - loss: 0.0365 - accuracy: 0.9819 - dice_coefficient: 0.9755 - iou: 0.9671 - val_loss: 0.0866 - val_accuracy: 0.9628 - val_dice_coefficient: 0.9570 - val_iou: 0.9470 - lr: 1.0240e-04\n",
      "Epoch 67/200\n",
      " 62/104 [================>.............] - ETA: 30s - loss: 0.0353 - accuracy: 0.9826 - dice_coefficient: 0.9760 - iou: 0.9679"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import datetime\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Fit the model\n",
    "callbacks = [\n",
    "    ModelCheckpoint('model_best.h5', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, min_lr=0.00001, verbose=1),\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "results = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=8, epochs=200,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTUroCf_DPEH",
    "outputId": "500dc7e2-6905-4612-bde3-078e808b01c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, d, i = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print out the performance metrics\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Dice Co-efficient: {d}\")\n",
    "print(f\"Test iou: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooF3o2OfD7x7"
   },
   "source": [
    "# **Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPLbStjBE_8b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Recall, Precision, MeanIoU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "\n",
    "smooth = 1e-6  # To avoid division by zero\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6  # To avoid division by zero\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = tf.keras.backend.sum(tf.keras.backend.abs(y_true) + tf.keras.backend.abs(y_pred), axis=-1)\n",
    "    iou = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return iou\n",
    "\n",
    "def combined_dice_crossentropy_loss(y_true, y_pred, dice_loss_weight=0.5):\n",
    "    # Dice Loss\n",
    "    dice_loss_value = dice_loss(y_true, y_pred)\n",
    "\n",
    "    # Categorical Cross-Entropy Loss\n",
    "    cross_entropy_loss_value = categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Combined Loss\n",
    "    combined_loss = dice_loss_weight * dice_loss_value + (1 - dice_loss_weight) * cross_entropy_loss_value\n",
    "    return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHG-qx51DPEI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "def get_input_array(image_path):\n",
    "  array = np.array(Image.open(image_path).convert(\"L\").resize((512, 512), Image.LANCZOS))\n",
    "  array = array.reshape(512, 512, 1)\n",
    "  array = array / 255\n",
    "  array = np.expand_dims(array, axis = 0) # Adding batch.\n",
    "  return array\n",
    "\n",
    "def get_probability_distro(input_array):\n",
    "  model_path = 'model_best.h5'\n",
    "  x = {\n",
    "      \"combined_dice_crossentropy_loss\": combined_dice_crossentropy_loss,\n",
    "      \"iou\": iou,\n",
    "      \"dice_coefficient\": dice_coefficient\n",
    "  }\n",
    "  model = load_model(model_path, custom_objects=x)\n",
    "  predictions = model.predict(input_array)\n",
    "\n",
    "  probability_distro = predictions[0]\n",
    "  return probability_distro\n",
    "\n",
    "def get_segmentation(probability_distro):\n",
    "  return np.argmax(probability_distro, axis = -1)\n",
    "\n",
    "def get_rgb_image(segmentation):\n",
    "  rgb_image = np.zeros((*segmentation.shape, 3), dtype=np.uint8)\n",
    "\n",
    "  colors = {\n",
    "      0: [0, 0, 0], # Black - BG\n",
    "      1: [127, 127, 127], # Grey - VAT\n",
    "      2: [255, 255, 255] # White - SAT\n",
    "  }\n",
    "\n",
    "  for class_index, color in colors.items():\n",
    "    rgb_image[segmentation == class_index] = color\n",
    "\n",
    "  return rgb_image\n",
    "\n",
    "def get_grayscale_image(segmentation):\n",
    "    grayscale_image = np.zeros(segmentation.shape, dtype=np.uint8)\n",
    "\n",
    "    intensities = {\n",
    "        0: 0,   # Black - BACKGROUND\n",
    "        1: 127, # Grey - VISCERAL_FAT\n",
    "        2: 255  # White - SUPERFICIAL_FAT\n",
    "    }\n",
    "\n",
    "    for class_index, intensity in intensities.items():\n",
    "        grayscale_image[segmentation == class_index] = intensity\n",
    "\n",
    "    return grayscale_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_gray_scale_image(gray_scale_image):\n",
    "    \"\"\"\n",
    "    This function converts only the white pixels within the interior of the ring to grey,\n",
    "    while preserving the white border and existing grey areas.\n",
    "    \"\"\"\n",
    "    # Define class values\n",
    "    BACKGROUND = 0  # Black\n",
    "    VISCERAL_FAT = 127  # Grey\n",
    "    SUPERFICIAL_FAT = 255  # White\n",
    "\n",
    "    # Step 1: Create a mask for the white (superficial fat) areas\n",
    "    white_mask = gray_scale_image == SUPERFICIAL_FAT\n",
    "\n",
    "    # Initialize a mask that will be used to fill contours\n",
    "    mask = np.zeros_like(gray_scale_image, dtype=np.uint8)\n",
    "\n",
    "    # Step 2: Find all contours on the white mask\n",
    "    contours, hierarchy = cv2.findContours(white_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Step 3: Fill the white areas that are not border (i.e., have a parent contour which is the border)\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Check if the contour has a parent contour\n",
    "        if hierarchy[0, i, 3] != -1:  # Has a parent contour\n",
    "            cv2.drawContours(mask, [contour], -1, 1, -1)\n",
    "\n",
    "    # Update segmentation image: convert the white to grey where mask is 1 and original pixel is not BACKGROUND\n",
    "    gray_scale_image = np.where((mask == 1) & (gray_scale_image != BACKGROUND), VISCERAL_FAT, gray_scale_image)\n",
    "\n",
    "    return gray_scale_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rNZu9c5JZM1",
    "outputId": "b3ca7778-a42e-4222-d34c-34e252c10f60"
   },
   "outputs": [],
   "source": [
    "input_array = get_input_array(\"test4.png\")\n",
    "probability_distro = get_probability_distro(input_array)\n",
    "segmentation = get_segmentation(probability_distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVYf4n9SWEbz"
   },
   "outputs": [],
   "source": [
    "gray_scale_image = get_grayscale_image(segmentation)\n",
    "final_image = clean_gray_scale_image(gray_scale_image.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "17YvUcYjuq4e",
    "outputId": "84651fe6-7d51-4f67-f41a-34c5ccecd8b6"
   },
   "outputs": [],
   "source": [
    "# Display the original and converted images\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(gray_scale_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Final image')\n",
    "plt.imshow(final_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "VDS6lRnLxSVw",
    "outputId": "5961c6fc-9a16-478d-eec7-dca51b59c74e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def convert_interior_white_to_grey(segmentation):\n",
    "#     \"\"\"\n",
    "#     This function converts only the white pixels within the interior of the ring to grey,\n",
    "#     while preserving the white border and existing grey areas.\n",
    "#     \"\"\"\n",
    "#     # Define class values\n",
    "#     BACKGROUND = 0  # Black\n",
    "#     VISCERAL_FAT = 128  # Grey\n",
    "#     SUPERFICIAL_FAT = 255  # White\n",
    "\n",
    "#     # Step 1: Create a mask for the white (superficial fat) areas\n",
    "#     white_mask = segmentation == 0\n",
    "\n",
    "#     # Step 2: Find all contours on the white mask\n",
    "#     contours, hierarchy = cv2.findContours(white_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     # Step 3: Fill the white areas that are not border (i.e., have a parent contour which is the border)\n",
    "#     for i, contour in enumerate(contours):\n",
    "#         # Check if the contour has a parent contour\n",
    "#         if hierarchy[0, i, 3] != -1:  # Has a parent contour\n",
    "#             cv2.drawContours(segmentation, [contour], -1, VISCERAL_FAT, -1)\n",
    "\n",
    "#     return segmentation\n",
    "\n",
    "# image = np.array(Image.open(\"a.png\").convert(\"L\"))\n",
    "# # Apply the conversion function to the original segmentation\n",
    "# converted_interior_segmentation = convert_interior_white_to_grey(image.copy())\n",
    "\n",
    "# # Display the original and converted images\n",
    "# plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title('Original Image')\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title('Converted Interior Segmentation')\n",
    "# plt.imshow(converted_interior_segmentation, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
